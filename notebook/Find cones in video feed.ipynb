{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import glob\n",
    "\n",
    "class Args(object):\n",
    "    debug = False\n",
    "    fromMain = False\n",
    "    image_dir = ''\n",
    "    video_file = ''\n",
    "\n",
    "args = Args()\n",
    "\n",
    "def is_cv2():\n",
    "    # if we are using OpenCV 2, then our cv2.__version__ will start\n",
    "    # with '2.'\n",
    "    return check_opencv_version(\"2.\")\n",
    "\n",
    "def is_cv3():\n",
    "    # if we are using OpenCV 3.X, then our cv2.__version__ will start\n",
    "    # with '3.'\n",
    "    return check_opencv_version(\"3.\")\n",
    "\n",
    "def check_opencv_version(major, lib=None):\n",
    "    # if the supplied library is None, import OpenCV\n",
    "    if lib is None:\n",
    "        import cv2 as lib\n",
    "\n",
    "    # return whether or not the current OpenCV version matches the\n",
    "    # major version number\n",
    "    return lib.__version__.startswith(major)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convexHullIsPointingUp(hull):\n",
    "    x, y, w, h = cv2.boundingRect(hull)\n",
    "\n",
    "    aspectRatio = float(w) / h\n",
    "    if aspectRatio > 0.9:\n",
    "        return False\n",
    "\n",
    "    listOfPointsAboveCenter = []\n",
    "    listOfPointsBelowCenter = []\n",
    "\n",
    "    intYcenter = y + h / 2\n",
    "\n",
    "    # step through all points in convex hull\n",
    "    for point in hull:\n",
    "        # and add each point to\n",
    "        # list of points above or below vertical center as applicable\n",
    "        if point[0][1] < intYcenter:\n",
    "            listOfPointsAboveCenter.append(point)\n",
    "\n",
    "        if point[0][1] >= intYcenter:\n",
    "            listOfPointsBelowCenter.append(point)\n",
    "\n",
    "    intLeftMostPointBelowCenter = listOfPointsBelowCenter[0][0][0]\n",
    "    intRightMostPointBelowCenter = listOfPointsBelowCenter[0][0][0]\n",
    "\n",
    "    # determine left most point below center\n",
    "    for point in listOfPointsBelowCenter:\n",
    "\n",
    "            if point[0][0] < intLeftMostPointBelowCenter:\n",
    "                intLeftMostPointBelowCenter = point[0][0]\n",
    "\n",
    "        # determine right most point below center\n",
    "    for point in listOfPointsBelowCenter:\n",
    "        if point[0][0] >= intRightMostPointBelowCenter:\n",
    "            intRightMostPointBelowCenter = point[0][0]\n",
    "\n",
    "        # step through all points above center\n",
    "    for point in listOfPointsAboveCenter:\n",
    "        if point[0][0] < intLeftMostPointBelowCenter or \\\n",
    "         point[0][0] > intRightMostPointBelowCenter:\n",
    "            return False\n",
    "\n",
    "    # if we get here, shape has passed pointing up check\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_cones(img):\n",
    "    h, w = img.shape[:2]\n",
    "    image_centerX = w/2\n",
    "    image_centerY = h  # y goes down from top\n",
    "    print(w, h, image_centerX, image_centerY)\n",
    "\n",
    "    # convert to HSV color space, this will produce better color filtering\n",
    "    imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Threshold on low range of HSV red\n",
    "    low_redl = np.array([0, 135, 135])\n",
    "    low_redh = np.array([15, 255, 255])\n",
    "    imgThreshLow = cv2.inRange(imgHSV, low_redl, low_redh)\n",
    "\n",
    "    # threshold on high range of HSV red\n",
    "    high_redl = np.array([159, 135, 135])\n",
    "    high_redh = np.array([179, 255, 255])\n",
    "    imgThreshHigh = cv2.inRange(imgHSV, high_redl, high_redh)\n",
    "\n",
    "    # combine low range red thresh and high range red thresh\n",
    "    imgThresh = cv2.bitwise_or(imgThreshLow, imgThreshHigh)\n",
    "\n",
    "    # clone/copy thresh image before smoothing\n",
    "    imgThreshSmoothed = imgThresh.copy()\n",
    "    # open image (erode, then dilate)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    imgThreshSmoothed = cv2.erode(imgThresh, kernel, iterations=1)\n",
    "    imgThreshSmoothed = cv2.dilate(imgThreshSmoothed, kernel, iterations=1)\n",
    "    # Gaussian blur\n",
    "    imgThreshSmoothed = cv2.GaussianBlur(imgThreshSmoothed, (5, 5), 0)\n",
    "    #cv2.imshow('imgThreshSmoothed ', imgThreshSmoothed)\n",
    "    # get Canny edges\n",
    "\n",
    "    imgCanny = cv2.Canny(imgThreshSmoothed, 160, 80)\n",
    "    #cv2.imshow('imgCanny ', imgCanny)\n",
    "    if is_cv2():\n",
    "        contours, hierarchy = cv2.findContours(imgCanny,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    else:\n",
    "        image, contours, hierarchy = cv2.findContours(imgCanny,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    listOfContours = []\n",
    "    if len(contours) != 0:\n",
    "        for cnt in contours:\n",
    "            # epsilon = 0.1 * cv2.arcLength(cnt, True)\n",
    "            # print'epsilon',epsilon\n",
    "            listOfContours.append(cv2.approxPolyDP(cnt, 6.7, True))\n",
    "\n",
    "    listOfCones = []\n",
    "    for contour in listOfContours:\n",
    "            hull = cv2.convexHull(contour)\n",
    "            # print 'convexHull',len(temp)\n",
    "            if (len(hull) >= 3 and convexHullIsPointingUp(hull)):\n",
    "                listOfCones.append(hull)\n",
    "                # y goes down the screen so y is larger closer to camera\n",
    "                x, y, w, h = cv2.boundingRect(hull)\n",
    "                newX = x + w/2 - image_centerX\n",
    "                # Height is being measured top of screen to down so we need to invert y\n",
    "                newY = image_centerY - (y+h)\n",
    "                # TODO: Fix the calculation\n",
    "                if(newY == 0):\n",
    "                  newY = 1\n",
    "                theta = (newX * 1.0) / newY\n",
    "                print(x, y, w, h, newX, newY, theta)\n",
    "           \n",
    "    imghull = img.copy()\n",
    "    cv2.drawContours(imghull, listOfCones, -1, (0, 255, 0), 3)\n",
    "    return len(listOfCones), imghull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def find_in_images(loc='../images'):\n",
    "    # get the files\n",
    "    files = glob.glob(loc + '/*.jpg')\n",
    "\n",
    "    print('Using dir %s' % loc)\n",
    "    for file in files:\n",
    "        print('File %s' % file)\n",
    "        count, imghull = find_cones(cv2.imread(file, -1))\n",
    "        msg_str = 'Found %d Cones' % count\n",
    "        print(msg_str)\n",
    "        plt.figure()\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(cv2.cvtColor(imghull, cv2.COLOR_BGR2RGB))\n",
    "        plt.show()        # Show the first image on the left column\n",
    "        \n",
    "    print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def find_in_video(fileName):\n",
    "    if(fileName == None):\n",
    "      cap = cv2.VideoCapture(0)\n",
    "    else:\n",
    "      cap = cv2.VideoCapture(fileName)\n",
    "      if(cap.isOpened() == False):\n",
    "        print(\"Error: Could not open video file %s. Using default device.\" % fileName)\n",
    "        cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if(cap.isOpened() == False):\n",
    "      print(\"Could not open default video device\")\n",
    "      return\n",
    "\n",
    "    #rate = rospy.Rate(1) # 1 frame per second\n",
    "    #while not rospy.is_shutdown():\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Display the resulting frame\n",
    "        if(ret):\n",
    "            count, imghull = find_cones(frame)\n",
    "            cv2.imshow('output', imghull)\n",
    "            print('Found %d Cones' % count)\n",
    "\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "        #rate.sleep()\n",
    "        time.sleep(1)\n",
    "\n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_cones_main():\n",
    "    print(args.debug, args.image_dir, args.video_file)\n",
    "    if args.image_dir:\n",
    "        args.debug = True\n",
    "        find_in_images(args.image_dir)\n",
    "    else:\n",
    "        find_in_video(args.video_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "args.debug = False\n",
    "#args.image_dir = '../images'\n",
    "args.image_dir = ''\n",
    "args.video_file = 0\n",
    "find_cones_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
